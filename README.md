# Airflow_flow
Learning Airflow


Spark 

We need Hadoop Cluster to Run Spark -- Seattle Data Guy 

Python Dag 

We Can Do fine with just local server 

Data Ingestion - Spark ( Pyspark ) 
Data Processing (ETL)- Pyspark Or PySpark in DataBricks Or Hive 
Data Orchestration - Airflow Or DataBricks Or Autosys 
Data Report - Tableau